{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tf\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        self.convolution = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(288, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.fc(x)\n",
    "        x = tf.dropout(x, p=0.2, training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_batch_size=50\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='./data/mnist_train', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=mnist_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data/mnist_test', train=False, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, batch_size, epoch_cnt, optimizer):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    batch_size = 50\n",
    "    i = 0\n",
    "    for epoch in range(epoch_cnt):\n",
    "        print('epoch: {}'.format(epoch))\n",
    "        for data, target in train_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = tf.cross_entropy(output, target)\n",
    "            loss.backward()    # calc gradients\n",
    "            train_loss.append(loss.data.item())\n",
    "            optimizer.step()   # update gradients\n",
    "            prediction = output.data.max(1)[1]   # first column has actual prob.\n",
    "            accuracy = prediction.eq(target.data).sum()/batch_size*100\n",
    "            train_acc.append(accuracy)\n",
    "            if i % 300 == 0:\n",
    "                print('Train Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(i, loss.data.item(), accuracy))\n",
    "            i += 1\n",
    "    return [train_acc, train_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Train Step: 0\tLoss: 2.307\tAccuracy: 12.000\n",
      "Train Step: 300\tLoss: 0.654\tAccuracy: 80.000\n",
      "Train Step: 600\tLoss: 0.492\tAccuracy: 86.000\n",
      "Train Step: 900\tLoss: 0.230\tAccuracy: 96.000\n",
      "epoch: 1\n",
      "Train Step: 1200\tLoss: 0.407\tAccuracy: 84.000\n",
      "Train Step: 1500\tLoss: 0.263\tAccuracy: 88.000\n",
      "Train Step: 1800\tLoss: 0.390\tAccuracy: 76.000\n",
      "Train Step: 2100\tLoss: 0.549\tAccuracy: 82.000\n",
      "epoch: 2\n",
      "Train Step: 2400\tLoss: 0.332\tAccuracy: 80.000\n",
      "Train Step: 2700\tLoss: 0.377\tAccuracy: 82.000\n",
      "Train Step: 3000\tLoss: 0.253\tAccuracy: 92.000\n",
      "Train Step: 3300\tLoss: 0.450\tAccuracy: 82.000\n",
      "epoch: 3\n",
      "Train Step: 3600\tLoss: 0.180\tAccuracy: 94.000\n",
      "Train Step: 3900\tLoss: 0.267\tAccuracy: 88.000\n",
      "Train Step: 4200\tLoss: 0.190\tAccuracy: 92.000\n",
      "Train Step: 4500\tLoss: 0.235\tAccuracy: 84.000\n",
      "epoch: 4\n",
      "Train Step: 4800\tLoss: 0.290\tAccuracy: 88.000\n",
      "Train Step: 5100\tLoss: 0.315\tAccuracy: 86.000\n",
      "Train Step: 5400\tLoss: 0.405\tAccuracy: 88.000\n",
      "Train Step: 5700\tLoss: 0.243\tAccuracy: 86.000\n",
      "epoch: 5\n",
      "Train Step: 6000\tLoss: 0.301\tAccuracy: 86.000\n",
      "Train Step: 6300\tLoss: 0.220\tAccuracy: 88.000\n",
      "Train Step: 6600\tLoss: 0.336\tAccuracy: 84.000\n",
      "Train Step: 6900\tLoss: 0.357\tAccuracy: 84.000\n",
      "epoch: 6\n",
      "Train Step: 7200\tLoss: 0.276\tAccuracy: 86.000\n",
      "Train Step: 7500\tLoss: 0.276\tAccuracy: 86.000\n",
      "Train Step: 7800\tLoss: 0.256\tAccuracy: 88.000\n",
      "Train Step: 8100\tLoss: 0.315\tAccuracy: 88.000\n",
      "epoch: 7\n",
      "Train Step: 8400\tLoss: 0.341\tAccuracy: 86.000\n",
      "Train Step: 8700\tLoss: 0.256\tAccuracy: 86.000\n",
      "Train Step: 9000\tLoss: 0.125\tAccuracy: 92.000\n",
      "Train Step: 9300\tLoss: 0.313\tAccuracy: 84.000\n",
      "epoch: 8\n",
      "Train Step: 9600\tLoss: 0.201\tAccuracy: 86.000\n",
      "Train Step: 9900\tLoss: 0.259\tAccuracy: 86.000\n",
      "Train Step: 10200\tLoss: 0.181\tAccuracy: 84.000\n",
      "Train Step: 10500\tLoss: 0.207\tAccuracy: 90.000\n",
      "epoch: 9\n",
      "Train Step: 10800\tLoss: 0.253\tAccuracy: 82.000\n",
      "Train Step: 11100\tLoss: 0.143\tAccuracy: 92.000\n",
      "Train Step: 11400\tLoss: 0.395\tAccuracy: 84.000\n",
      "Train Step: 11700\tLoss: 0.244\tAccuracy: 84.000\n"
     ]
    }
   ],
   "source": [
    "mnist_model = MnistModel()\n",
    "optimizer = optim.Adam(mnist_model.parameters(), lr=0.0001)\n",
    "[mnist_acc, mnist_loss] = train(model=mnist_model, train_loader=mnist_train_loader, batch_size=mnist_batch_size, epoch_cnt=10, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        prediction = output.data.max(1)[1]\n",
    "        correct += prediction.eq(target.data).sum()\n",
    "    print('\\nTest set: Accuracy: {:.2f}%'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/yt92tvfx4dg7s1cn2l6wtk09xzv94b/T/ipykernel_13741/2084227670.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 98.85%\n"
     ]
    }
   ],
   "source": [
    "eval(model=mnist_model, test_loader=mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for step in range(len(mnist_loss)):\n",
    "    writer.add_scalar('train/mnist_loss', mnist_loss[step], step)\n",
    "    writer.add_scalar('train/mnist_accuracy', mnist_acc[step], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_batch_size=50\n",
    "fashion_mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(root='./data/fashion_mnist_train', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=fashion_mnist_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "fashion_mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data/fashion_mnist_test', train=False, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Train Step: 0\tLoss: 2.318\tAccuracy: 10.000\n",
      "Train Step: 300\tLoss: 0.993\tAccuracy: 60.000\n",
      "Train Step: 600\tLoss: 1.087\tAccuracy: 54.000\n",
      "Train Step: 900\tLoss: 0.741\tAccuracy: 64.000\n",
      "epoch: 1\n",
      "Train Step: 1200\tLoss: 0.844\tAccuracy: 64.000\n",
      "Train Step: 1500\tLoss: 0.977\tAccuracy: 64.000\n",
      "Train Step: 1800\tLoss: 0.699\tAccuracy: 74.000\n",
      "Train Step: 2100\tLoss: 0.818\tAccuracy: 68.000\n",
      "epoch: 2\n",
      "Train Step: 2400\tLoss: 0.793\tAccuracy: 62.000\n",
      "Train Step: 2700\tLoss: 0.832\tAccuracy: 68.000\n",
      "Train Step: 3000\tLoss: 0.705\tAccuracy: 72.000\n",
      "Train Step: 3300\tLoss: 0.469\tAccuracy: 82.000\n",
      "epoch: 3\n",
      "Train Step: 3600\tLoss: 0.632\tAccuracy: 78.000\n",
      "Train Step: 3900\tLoss: 0.920\tAccuracy: 76.000\n",
      "Train Step: 4200\tLoss: 0.667\tAccuracy: 72.000\n",
      "Train Step: 4500\tLoss: 0.542\tAccuracy: 84.000\n",
      "epoch: 4\n",
      "Train Step: 4800\tLoss: 0.487\tAccuracy: 84.000\n",
      "Train Step: 5100\tLoss: 0.871\tAccuracy: 70.000\n",
      "Train Step: 5400\tLoss: 0.711\tAccuracy: 82.000\n",
      "Train Step: 5700\tLoss: 0.641\tAccuracy: 68.000\n",
      "epoch: 5\n",
      "Train Step: 6000\tLoss: 0.558\tAccuracy: 80.000\n",
      "Train Step: 6300\tLoss: 0.720\tAccuracy: 72.000\n",
      "Train Step: 6600\tLoss: 0.631\tAccuracy: 78.000\n",
      "Train Step: 6900\tLoss: 0.566\tAccuracy: 78.000\n",
      "epoch: 6\n",
      "Train Step: 7200\tLoss: 0.804\tAccuracy: 68.000\n",
      "Train Step: 7500\tLoss: 0.631\tAccuracy: 72.000\n",
      "Train Step: 7800\tLoss: 0.474\tAccuracy: 78.000\n",
      "Train Step: 8100\tLoss: 0.462\tAccuracy: 74.000\n",
      "epoch: 7\n",
      "Train Step: 8400\tLoss: 0.410\tAccuracy: 82.000\n",
      "Train Step: 8700\tLoss: 0.495\tAccuracy: 80.000\n",
      "Train Step: 9000\tLoss: 0.575\tAccuracy: 68.000\n",
      "Train Step: 9300\tLoss: 0.718\tAccuracy: 66.000\n",
      "epoch: 8\n",
      "Train Step: 9600\tLoss: 0.458\tAccuracy: 82.000\n",
      "Train Step: 9900\tLoss: 0.641\tAccuracy: 80.000\n",
      "Train Step: 10200\tLoss: 0.478\tAccuracy: 80.000\n",
      "Train Step: 10500\tLoss: 0.572\tAccuracy: 78.000\n",
      "epoch: 9\n",
      "Train Step: 10800\tLoss: 0.438\tAccuracy: 80.000\n",
      "Train Step: 11100\tLoss: 0.847\tAccuracy: 66.000\n",
      "Train Step: 11400\tLoss: 0.515\tAccuracy: 82.000\n",
      "Train Step: 11700\tLoss: 0.330\tAccuracy: 88.000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_model = MnistModel()\n",
    "fashion_mnist_optimizer = optim.Adam(fashion_mnist_model.parameters(), lr=0.0001)\n",
    "[fashion_mnist_acc, fashion_mnist_loss] = train(\n",
    "    model=fashion_mnist_model,\n",
    "    train_loader=fashion_mnist_train_loader,\n",
    "    batch_size=fashion_mnist_batch_size,\n",
    "    epoch_cnt=10,\n",
    "    optimizer=fashion_mnist_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/yt92tvfx4dg7s1cn2l6wtk09xzv94b/T/ipykernel_13741/2084227670.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 88.22%\n"
     ]
    }
   ],
   "source": [
    "eval(model=fashion_mnist_model, test_loader=fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for step in range(len(fashion_mnist_loss)):\n",
    "    writer.add_scalar('train/fashion_mnist_loss', fashion_mnist_loss[step], step)\n",
    "    writer.add_scalar('train/fashion_mnist_accuracy', fashion_mnist_acc[step], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mnist_model, 'mnist_model.pt')\n",
    "torch.save(fashion_mnist_model, 'fashion_mnist_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Train Step: 0\tLoss: 4.879\tAccuracy: 8.000\n",
      "Train Step: 300\tLoss: 0.885\tAccuracy: 66.000\n",
      "Train Step: 600\tLoss: 0.805\tAccuracy: 74.000\n",
      "Train Step: 900\tLoss: 0.790\tAccuracy: 68.000\n",
      "epoch: 1\n",
      "Train Step: 1200\tLoss: 0.902\tAccuracy: 64.000\n",
      "Train Step: 1500\tLoss: 0.810\tAccuracy: 72.000\n",
      "Train Step: 1800\tLoss: 0.814\tAccuracy: 70.000\n",
      "Train Step: 2100\tLoss: 0.547\tAccuracy: 78.000\n",
      "epoch: 2\n",
      "Train Step: 2400\tLoss: 0.863\tAccuracy: 72.000\n",
      "Train Step: 2700\tLoss: 0.417\tAccuracy: 82.000\n",
      "Train Step: 3000\tLoss: 0.726\tAccuracy: 72.000\n",
      "Train Step: 3300\tLoss: 0.458\tAccuracy: 74.000\n",
      "epoch: 3\n",
      "Train Step: 3600\tLoss: 0.592\tAccuracy: 80.000\n",
      "Train Step: 3900\tLoss: 0.658\tAccuracy: 72.000\n",
      "Train Step: 4200\tLoss: 0.516\tAccuracy: 76.000\n",
      "Train Step: 4500\tLoss: 0.893\tAccuracy: 66.000\n",
      "epoch: 4\n",
      "Train Step: 4800\tLoss: 0.500\tAccuracy: 78.000\n",
      "Train Step: 5100\tLoss: 0.665\tAccuracy: 72.000\n",
      "Train Step: 5400\tLoss: 0.613\tAccuracy: 84.000\n",
      "Train Step: 5700\tLoss: 0.586\tAccuracy: 68.000\n",
      "epoch: 5\n",
      "Train Step: 6000\tLoss: 0.578\tAccuracy: 76.000\n",
      "Train Step: 6300\tLoss: 0.642\tAccuracy: 78.000\n",
      "Train Step: 6600\tLoss: 0.535\tAccuracy: 76.000\n",
      "Train Step: 6900\tLoss: 0.460\tAccuracy: 82.000\n",
      "epoch: 6\n",
      "Train Step: 7200\tLoss: 0.615\tAccuracy: 76.000\n",
      "Train Step: 7500\tLoss: 0.332\tAccuracy: 86.000\n",
      "Train Step: 7800\tLoss: 0.443\tAccuracy: 82.000\n",
      "Train Step: 8100\tLoss: 0.506\tAccuracy: 76.000\n",
      "epoch: 7\n",
      "Train Step: 8400\tLoss: 0.480\tAccuracy: 82.000\n",
      "Train Step: 8700\tLoss: 0.479\tAccuracy: 80.000\n",
      "Train Step: 9000\tLoss: 0.533\tAccuracy: 84.000\n",
      "Train Step: 9300\tLoss: 0.576\tAccuracy: 76.000\n",
      "epoch: 8\n",
      "Train Step: 9600\tLoss: 0.523\tAccuracy: 80.000\n",
      "Train Step: 9900\tLoss: 0.526\tAccuracy: 78.000\n",
      "Train Step: 10200\tLoss: 0.532\tAccuracy: 78.000\n",
      "Train Step: 10500\tLoss: 0.715\tAccuracy: 76.000\n",
      "epoch: 9\n",
      "Train Step: 10800\tLoss: 0.568\tAccuracy: 78.000\n",
      "Train Step: 11100\tLoss: 0.394\tAccuracy: 86.000\n",
      "Train Step: 11400\tLoss: 0.744\tAccuracy: 68.000\n",
      "Train Step: 11700\tLoss: 0.499\tAccuracy: 80.000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_pt_model = torch.load('mnist_model.pt')\n",
    "fashion_mnist_pt_optimizer = optim.Adam(fashion_mnist_pt_model.parameters(), lr=0.0001)\n",
    "[fashion_mnist_pt_acc, fashion_mnist_pt_loss] = train(\n",
    "    model=fashion_mnist_pt_model,\n",
    "    train_loader=fashion_mnist_train_loader,\n",
    "    batch_size=fashion_mnist_batch_size,\n",
    "    epoch_cnt=10,\n",
    "    optimizer=fashion_mnist_pt_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/yt92tvfx4dg7s1cn2l6wtk09xzv94b/T/ipykernel_13741/2084227670.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "eval(model=fashion_mnist_pt_model, test_loader=fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for step in range(len(fashion_mnist_pt_loss)):\n",
    "    writer.add_scalar('train/fashion_mnist_pt_loss', fashion_mnist_pt_loss[step], step)\n",
    "    writer.add_scalar('train/fashion_mnist_pt_accuracy', fashion_mnist_pt_acc[step], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Train Step: 0\tLoss: 5.147\tAccuracy: 14.000\n",
      "Train Step: 300\tLoss: 1.184\tAccuracy: 64.000\n",
      "Train Step: 600\tLoss: 1.067\tAccuracy: 58.000\n",
      "Train Step: 900\tLoss: 0.920\tAccuracy: 56.000\n",
      "epoch: 1\n",
      "Train Step: 1200\tLoss: 0.807\tAccuracy: 72.000\n",
      "Train Step: 1500\tLoss: 1.084\tAccuracy: 68.000\n",
      "Train Step: 1800\tLoss: 0.572\tAccuracy: 78.000\n",
      "Train Step: 2100\tLoss: 0.787\tAccuracy: 68.000\n",
      "epoch: 2\n",
      "Train Step: 2400\tLoss: 0.740\tAccuracy: 74.000\n",
      "Train Step: 2700\tLoss: 0.973\tAccuracy: 58.000\n",
      "Train Step: 3000\tLoss: 0.885\tAccuracy: 64.000\n",
      "Train Step: 3300\tLoss: 0.933\tAccuracy: 56.000\n",
      "epoch: 3\n",
      "Train Step: 3600\tLoss: 0.797\tAccuracy: 64.000\n",
      "Train Step: 3900\tLoss: 0.723\tAccuracy: 70.000\n",
      "Train Step: 4200\tLoss: 0.779\tAccuracy: 66.000\n",
      "Train Step: 4500\tLoss: 0.791\tAccuracy: 70.000\n",
      "epoch: 4\n",
      "Train Step: 4800\tLoss: 0.700\tAccuracy: 68.000\n",
      "Train Step: 5100\tLoss: 0.530\tAccuracy: 78.000\n",
      "Train Step: 5400\tLoss: 0.663\tAccuracy: 76.000\n",
      "Train Step: 5700\tLoss: 0.754\tAccuracy: 68.000\n",
      "epoch: 5\n",
      "Train Step: 6000\tLoss: 0.686\tAccuracy: 68.000\n",
      "Train Step: 6300\tLoss: 0.377\tAccuracy: 82.000\n",
      "Train Step: 6600\tLoss: 0.717\tAccuracy: 72.000\n",
      "Train Step: 6900\tLoss: 0.686\tAccuracy: 80.000\n",
      "epoch: 6\n",
      "Train Step: 7200\tLoss: 0.703\tAccuracy: 68.000\n",
      "Train Step: 7500\tLoss: 0.847\tAccuracy: 72.000\n",
      "Train Step: 7800\tLoss: 0.513\tAccuracy: 80.000\n",
      "Train Step: 8100\tLoss: 0.762\tAccuracy: 74.000\n",
      "epoch: 7\n",
      "Train Step: 8400\tLoss: 0.591\tAccuracy: 72.000\n",
      "Train Step: 8700\tLoss: 0.456\tAccuracy: 88.000\n",
      "Train Step: 9000\tLoss: 0.537\tAccuracy: 78.000\n",
      "Train Step: 9300\tLoss: 0.691\tAccuracy: 72.000\n",
      "epoch: 8\n",
      "Train Step: 9600\tLoss: 0.642\tAccuracy: 70.000\n",
      "Train Step: 9900\tLoss: 0.580\tAccuracy: 76.000\n",
      "Train Step: 10200\tLoss: 0.650\tAccuracy: 76.000\n",
      "Train Step: 10500\tLoss: 0.624\tAccuracy: 74.000\n",
      "epoch: 9\n",
      "Train Step: 10800\tLoss: 0.756\tAccuracy: 70.000\n",
      "Train Step: 11100\tLoss: 0.551\tAccuracy: 82.000\n",
      "Train Step: 11400\tLoss: 0.411\tAccuracy: 88.000\n",
      "Train Step: 11700\tLoss: 0.759\tAccuracy: 80.000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_freeze_model = torch.load('mnist_model.pt')\n",
    "for param in fashion_mnist_freeze_model.convolution.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fashion_mnist_freeze_optimizer = optim.Adam(fashion_mnist_freeze_model.parameters(), lr=0.0001)\n",
    "[fashion_mnist_freeze_acc, fashion_mnist_freeze_loss] = train(\n",
    "    model=fashion_mnist_freeze_model,\n",
    "    train_loader=fashion_mnist_train_loader,\n",
    "    batch_size=fashion_mnist_batch_size,\n",
    "    epoch_cnt=10,\n",
    "    optimizer=fashion_mnist_freeze_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/yt92tvfx4dg7s1cn2l6wtk09xzv94b/T/ipykernel_13741/2084227670.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 84.29%\n"
     ]
    }
   ],
   "source": [
    "eval(model=fashion_mnist_freeze_model, test_loader=fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for step in range(len(fashion_mnist_freeze_loss)):\n",
    "    writer.add_scalar('train/fashion_mnist_freeze_loss', fashion_mnist_freeze_loss[step], step)\n",
    "    writer.add_scalar('train/fashion_mnist_freeze_accuracy', fashion_mnist_freeze_acc[step], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Train Step: 0\tLoss: 5.363\tAccuracy: 20.000\n",
      "Train Step: 300\tLoss: 1.271\tAccuracy: 64.000\n",
      "Train Step: 600\tLoss: 1.069\tAccuracy: 72.000\n",
      "Train Step: 900\tLoss: 0.702\tAccuracy: 78.000\n",
      "epoch: 1\n",
      "Train Step: 1200\tLoss: 0.855\tAccuracy: 70.000\n",
      "Train Step: 1500\tLoss: 1.059\tAccuracy: 48.000\n",
      "Train Step: 1800\tLoss: 0.827\tAccuracy: 74.000\n",
      "Train Step: 2100\tLoss: 0.701\tAccuracy: 72.000\n",
      "epoch: 2\n",
      "Train Step: 2400\tLoss: 0.858\tAccuracy: 60.000\n",
      "Train Step: 2700\tLoss: 0.994\tAccuracy: 54.000\n",
      "Train Step: 3000\tLoss: 0.839\tAccuracy: 68.000\n",
      "Train Step: 3300\tLoss: 0.778\tAccuracy: 70.000\n",
      "epoch: 0\n",
      "Train Step: 0\tLoss: 0.891\tAccuracy: 74.000\n",
      "Train Step: 300\tLoss: 0.775\tAccuracy: 70.000\n",
      "Train Step: 600\tLoss: 0.757\tAccuracy: 66.000\n",
      "Train Step: 900\tLoss: 0.548\tAccuracy: 76.000\n",
      "epoch: 1\n",
      "Train Step: 1200\tLoss: 0.651\tAccuracy: 76.000\n",
      "Train Step: 1500\tLoss: 0.601\tAccuracy: 78.000\n",
      "Train Step: 1800\tLoss: 0.570\tAccuracy: 74.000\n",
      "Train Step: 2100\tLoss: 0.578\tAccuracy: 74.000\n",
      "epoch: 2\n",
      "Train Step: 2400\tLoss: 0.608\tAccuracy: 78.000\n",
      "Train Step: 2700\tLoss: 0.386\tAccuracy: 84.000\n",
      "Train Step: 3000\tLoss: 0.435\tAccuracy: 82.000\n",
      "Train Step: 3300\tLoss: 0.670\tAccuracy: 72.000\n",
      "epoch: 3\n",
      "Train Step: 3600\tLoss: 0.677\tAccuracy: 72.000\n",
      "Train Step: 3900\tLoss: 0.627\tAccuracy: 76.000\n",
      "Train Step: 4200\tLoss: 0.657\tAccuracy: 72.000\n",
      "Train Step: 4500\tLoss: 0.562\tAccuracy: 76.000\n",
      "epoch: 4\n",
      "Train Step: 4800\tLoss: 0.671\tAccuracy: 82.000\n",
      "Train Step: 5100\tLoss: 0.516\tAccuracy: 78.000\n",
      "Train Step: 5400\tLoss: 0.504\tAccuracy: 78.000\n",
      "Train Step: 5700\tLoss: 0.286\tAccuracy: 92.000\n",
      "epoch: 5\n",
      "Train Step: 6000\tLoss: 0.434\tAccuracy: 76.000\n",
      "Train Step: 6300\tLoss: 0.594\tAccuracy: 80.000\n",
      "Train Step: 6600\tLoss: 0.867\tAccuracy: 74.000\n",
      "Train Step: 6900\tLoss: 0.727\tAccuracy: 72.000\n",
      "epoch: 6\n",
      "Train Step: 7200\tLoss: 0.537\tAccuracy: 84.000\n",
      "Train Step: 7500\tLoss: 0.315\tAccuracy: 88.000\n",
      "Train Step: 7800\tLoss: 0.366\tAccuracy: 88.000\n",
      "Train Step: 8100\tLoss: 0.266\tAccuracy: 86.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fashion_mnist_freeze_unfreeze_model = torch.load('mnist_model.pt')\n",
    "for param in fashion_mnist_freeze_unfreeze_model.convolution.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fashion_mnist_freeze_unfreeze_optimizer = optim.Adam(fashion_mnist_freeze_unfreeze_model.parameters(), lr=0.0001)\n",
    "train(\n",
    "    model=fashion_mnist_freeze_unfreeze_model,\n",
    "    train_loader=fashion_mnist_train_loader,\n",
    "    batch_size=fashion_mnist_batch_size,\n",
    "    epoch_cnt=3,\n",
    "    optimizer=fashion_mnist_freeze_unfreeze_optimizer\n",
    ")\n",
    "\n",
    "for param in fashion_mnist_freeze_unfreeze_model.convolution.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "[fashion_mnist_freeze_unfreeze_acc, fashion_mnist_freeze_unfreeze_loss] = train(\n",
    "    model=fashion_mnist_freeze_unfreeze_model,\n",
    "    train_loader=fashion_mnist_train_loader,\n",
    "    batch_size=fashion_mnist_batch_size,\n",
    "    epoch_cnt=7,\n",
    "    optimizer=fashion_mnist_freeze_unfreeze_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/yt92tvfx4dg7s1cn2l6wtk09xzv94b/T/ipykernel_13741/2084227670.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 88.19%\n"
     ]
    }
   ],
   "source": [
    "eval(model=fashion_mnist_freeze_unfreeze_model, test_loader=fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for step in range(len(fashion_mnist_freeze_unfreeze_loss)):\n",
    "    writer.add_scalar('train/fashion_mnist_freeze_unfreeze_loss', fashion_mnist_freeze_unfreeze_loss[step], step)\n",
    "    writer.add_scalar('train/fashion_mnist_freeze_unfreeze_accuracy', fashion_mnist_freeze_unfreeze_acc[step], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fab21ff72d727d73\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fab21ff72d727d73\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
